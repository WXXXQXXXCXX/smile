{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "smile.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WXXXQXXXCXX/smile/blob/vgg_model_1/smile.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qEuH1t0vTE0S",
        "outputId": "86193a02-04b4-4d47-ca67-64730416ebeb"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AK_ZSE8vTvBm"
      },
      "source": [
        "!pip install keras_vggface"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dhfn-AH_Vhyy"
      },
      "source": [
        "!pip install keras_applications"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tyxi4OtR8S9g"
      },
      "source": [
        "! pip install memory_profiler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ky5CPo1HT1O6"
      },
      "source": [
        "import keras\n",
        "from collections import defaultdict\n",
        "from glob import glob\n",
        "from random import choice, sample\n",
        "from keras.preprocessing import image\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
        "from keras.layers import Input, Dense, GlobalMaxPool2D, GlobalAvgPool2D, Concatenate, Multiply, Dropout, Subtract, LeakyReLU\n",
        "from keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow as tf\n",
        "from memory_profiler import memory_usage"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDCF8i_tUTNc"
      },
      "source": [
        "from keras_vggface.utils import preprocess_input\n",
        "from keras_vggface.vggface import VGGFace\n",
        "# keras.utils.layer_utils"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CdPjKk0Q6SUq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58514a8c-db91-4c43-c35a-8150721bec8b"
      },
      "source": [
        "!pip install kaggle"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (1.5.12)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle) (5.0.2)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle) (2021.10.8)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle) (4.62.3)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (3.0.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6zVppr76Vu7"
      },
      "source": [
        "!mkdir ~/.kaggle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBX7Jx8e6cI0"
      },
      "source": [
        "! cp kaggle.json ~/.kaggle/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xElMd7A06nML"
      },
      "source": [
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VvmtwRZc6wsj"
      },
      "source": [
        "!kaggle competitions download recognizing-faces-in-the-wild"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "euTjvdNJ61ao"
      },
      "source": [
        "! unzip train-faces"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMdoIm-kaaRe"
      },
      "source": [
        "train_file_path = \"train_relationships.csv\"\n",
        "val_famillies = \"F09\"\n",
        "all_images = glob(\"*/*/*.jpg\")\n",
        "train_images = [x for x in all_images if val_famillies not in x]\n",
        "val_images = [x for x in all_images if val_famillies in x]\n",
        "train_person_to_images_map = defaultdict(list)\n",
        "\n",
        "ppl = [x.split(\"/\")[-3] + \"/\" + x.split(\"/\")[-2] for x in all_images]\n",
        "\n",
        "for x in train_images:\n",
        "    train_person_to_images_map[x.split(\"/\")[-3] + \"/\" + x.split(\"/\")[-2]].append(x)\n",
        "\n",
        "val_person_to_images_map = defaultdict(list)\n",
        "\n",
        "for x in val_images:\n",
        "    val_person_to_images_map[x.split(\"/\")[-3] + \"/\" + x.split(\"/\")[-2]].append(x)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6k-UswjZa4Pk"
      },
      "source": [
        "relationships = pd.read_csv(train_file_path)\n",
        "relationships = list(zip(relationships.p1.values, relationships.p2.values))\n",
        "relationships = [x for x in relationships if x[0] in ppl and x[1] in ppl]\n",
        "\n",
        "train = [x for x in relationships if val_famillies not in x[0]]\n",
        "val = [x for x in relationships if val_famillies in x[0]]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7C9DyA0zvVUF"
      },
      "source": [
        "# hyperparameters\n",
        "EPOCH = 50\n",
        "BATCHSIZE = 16"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcWWUarqb8YA"
      },
      "source": [
        "def read_img(path):\n",
        "    img = image.load_img(path, target_size=(197, 197))\n",
        "    img = np.array(img).astype(np.float)\n",
        "    return preprocess_input(img, version=2)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXkoEwq7PA5_"
      },
      "source": [
        "class DataGenerator(tf.keras.utils.Sequence):\n",
        "  def __init__(self,list_tuples, person_to_images_map, batch_size=16):\n",
        "    self.list_tuples=list_tuples\n",
        "    self.person_to_images_map=person_to_images_map\n",
        "    self.batch_size=batch_size\n",
        "    self.ppl=list(person_to_images_map.keys())\n",
        "\n",
        "  def __len__(self):\n",
        "    return int(np.floor(len(self.list_tuples) / self.batch_size))\n",
        "\n",
        "  def __getitem__(self,index):\n",
        "        'Generate one batch of data'\n",
        "        batch_tuples = sample(self.list_tuples, self.batch_size // 2)\n",
        "        labels = [1] * len(batch_tuples)\n",
        "        while len(batch_tuples) < self.batch_size:\n",
        "            p1 = choice(self.ppl)\n",
        "            p2 = choice(self.ppl)\n",
        "\n",
        "            if p1 != p2 and (p1, p2) not in self.list_tuples and (p2, p1) not in self.list_tuples:\n",
        "                batch_tuples.append((p1, p2))\n",
        "                labels.append(0)\n",
        "\n",
        "        for x in batch_tuples:\n",
        "            if not len(self.person_to_images_map[x[0]]):\n",
        "                print(x[0])\n",
        "\n",
        "        X1 = [choice(self.person_to_images_map[x[0]]) for x in batch_tuples]\n",
        "        X1 = np.array([read_img(x) for x in X1])\n",
        "\n",
        "        X2 = [choice(self.person_to_images_map[x[1]]) for x in batch_tuples]\n",
        "        X2 = np.array([read_img(x) for x in X2])\n",
        "\n",
        "        return [X1, X2], np.array(labels)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19lB-ObKuEUK"
      },
      "source": [
        "\"\"\"\n",
        "result=model.fit(gen(train, train_person_to_images_map, batch_size=16), use_multiprocessing=True,\n",
        "                    validation_data=gen(val, val_person_to_images_map, batch_size=16), epochs=92, verbose=1,\n",
        "                    workers = 4, callbacks=callbacks_list, steps_per_epoch=200, validation_steps=100)\n",
        "\"\"\"\n",
        "def genOnetime(list_tuples, person_to_images_map, epochs=EPOCH, batch_size=16):\n",
        "    ppl = list(person_to_images_map.keys())\n",
        "    resultData1 = []\n",
        "    resultData2 = []\n",
        "    resultLabels = []\n",
        "    for epoch in range(epochs):\n",
        "        batch_tuples = sample(list_tuples, batch_size // 2)\n",
        "        labels = [1] * len(batch_tuples)\n",
        "        while len(batch_tuples) < batch_size:\n",
        "            p1 = choice(ppl)\n",
        "            p2 = choice(ppl)\n",
        "\n",
        "            if p1 != p2 and (p1, p2) not in list_tuples and (p2, p1) not in list_tuples:\n",
        "                batch_tuples.append((p1, p2))\n",
        "                labels.append(0)\n",
        "\n",
        "        for x in batch_tuples:\n",
        "            if not len(person_to_images_map[x[0]]):\n",
        "                print(x[0])\n",
        "\n",
        "        X1 = [choice(person_to_images_map[x[0]]) for x in batch_tuples]\n",
        "        X1 = np.array([read_img(x) for x in X1])\n",
        "\n",
        "        X2 = [choice(person_to_images_map[x[1]]) for x in batch_tuples]\n",
        "        X2 = np.array([read_img(x) for x in X2])\n",
        "\n",
        "        resultData1.extend(X1)\n",
        "        resultData2.extend(X2)\n",
        "        resultLabels.extend(labels)\n",
        "    resultData1 = np.array(resultData1)\n",
        "    resultData2 = np.array(resultData2)\n",
        "    resultLabels = np.array(resultLabels)\n",
        "    return [resultData1,resultData2], resultLabels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0J97IPOUcKnR"
      },
      "source": [
        "\n",
        "def baseline_model(learning_rate=0.001, beta1=0.9, beta2=0.99):\n",
        "    input_1 = Input(shape=(197, 197, 3))\n",
        "    input_2 = Input(shape=(197, 197, 3))\n",
        "\n",
        "    base_model = VGGFace(model='resnet50', include_top=False)\n",
        "\n",
        "    for x in base_model.layers:\n",
        "        x.trainable = False\n",
        "\n",
        "    x1 = base_model(input_1)\n",
        "    x2 = base_model(input_2)\n",
        "\n",
        "    x1 = Concatenate(axis=-1)([GlobalMaxPool2D()(x1), GlobalAvgPool2D()(x1)])\n",
        "    x2 = Concatenate(axis=-1)([GlobalMaxPool2D()(x2), GlobalAvgPool2D()(x2)])\n",
        "\n",
        "    x3 = Subtract()([x1, x2])\n",
        "    x3 = Multiply()([x3, x3])\n",
        "\n",
        "    x1_ = Multiply()([x1, x1])\n",
        "    x2_ = Multiply()([x2, x2])\n",
        "    x4 = Subtract()([x1_, x2_])\n",
        "    x = Concatenate(axis=-1)([x4, x3])\n",
        "\n",
        "    x = Dense(48, activation='relu')(x)\n",
        "    #x = LeakyReLU(alpha=0.1)(x)\n",
        "    x = Dropout(0.01)(x)\n",
        "    x = Dense(16, activation='relu')(x)\n",
        "    #x = LeakyReLU(alpha=0.1)(x)\n",
        "    x = Dropout(0.01)(x)\n",
        "    out = Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "    model = Model([input_1, input_2], out)\n",
        "    adam=Adam(learning_rate=learning_rate, beta_1=beta1, beta_2=beta2)\n",
        "    model.compile(loss=\"binary_crossentropy\", metrics=['acc'], optimizer=adam)\n",
        "\n",
        "    model.summary()\n",
        "\n",
        "    return model"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwLmiWQsyBQK"
      },
      "source": [
        "import gc\n",
        "from tensorflow.keras import backend as k\n",
        "from tensorflow.keras.callbacks import Callback\n",
        "from tensorflow.python.keras import backend as K\n",
        "config = tf.compat.v1.ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "config.gpu_options.per_process_gpu_memory_fraction = 0.24\n",
        "config.gpu_options.visible_device_list = \"0\"\n",
        "K.set_session(tf.compat.v1.Session(config=config))\n",
        "class ClearSessionCallback(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        print(f'Memory usage after: {memory_usage()}MB')\n",
        "        gc.collect()\n",
        "        k.clear_session()\n",
        "        print(f'Memory usage after clean up: {memory_usage()}MB')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "akYN3MDxcNhS"
      },
      "source": [
        "file_path = \"vgg_face.h5\"\n",
        "\n",
        "checkpoint = ModelCheckpoint(file_path, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "reduce_on_plateau = ReduceLROnPlateau(monitor=\"val_acc\", mode=\"max\", factor=0.1, patience=10, verbose=1)\n",
        "clear_session=ClearSessionCallback()\n",
        "earlyStopping=EarlyStopping(monitor=\"val_loss\",mode=\"min\",patience=25)\n",
        "\n",
        "callbacks_list = [checkpoint, reduce_on_plateau, clear_session, earlyStopping]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJKgWTovwKXx"
      },
      "source": [
        "trdata, trtarget = genOnetime(train, train_person_to_images_map, epochs=EPOCH , batch_size=BATCHSIZE)\n",
        "valdata, valtarget = genOnetime(val, val_person_to_images_map, epochs=EPOCH, batch_size=BATCHSIZE)\n",
        "result=model.fit(x=trdata, y=trtarget, use_multiprocessing=True,\n",
        "                    validation_data=(valdata, valtarget), epochs=EPOCH, verbose=1,\n",
        "                    workers = 4, callbacks=callbacks_list, steps_per_epoch=200, validation_steps=100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AB5kOSiJSlPQ",
        "outputId": "853a9dce-4b53-4162-e3ea-7a67c1c1c966"
      },
      "source": [
        "train_gen=DataGenerator(train,train_person_to_images_map,16)\n",
        "val_gen=DataGenerator(val,val_person_to_images_map,16)\n",
        "r=-2*np.random.rand()-2\n",
        "lr=pow(10,r)\n",
        "print(lr,r)\n",
        "model=baseline_model(0.0001)\n",
        "result=model.fit(train_gen, use_multiprocessing=True,\n",
        "          validation_data=val_gen, epochs=100, verbose=1,\n",
        "          workers = 4, callbacks=callbacks_list, steps_per_epoch=180, validation_steps=80)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0021926798181286784 -2.659024780712772\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 197, 197, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, 197, 197, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " vggface_resnet50 (Functional)  (None, None, None,   23561152    ['input_1[0][0]',                \n",
            "                                2048)                             'input_2[0][0]']                \n",
            "                                                                                                  \n",
            " global_max_pooling2d (GlobalMa  (None, 2048)        0           ['vggface_resnet50[0][0]']       \n",
            " xPooling2D)                                                                                      \n",
            "                                                                                                  \n",
            " global_average_pooling2d (Glob  (None, 2048)        0           ['vggface_resnet50[0][0]']       \n",
            " alAveragePooling2D)                                                                              \n",
            "                                                                                                  \n",
            " global_max_pooling2d_1 (Global  (None, 2048)        0           ['vggface_resnet50[1][0]']       \n",
            " MaxPooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " global_average_pooling2d_1 (Gl  (None, 2048)        0           ['vggface_resnet50[1][0]']       \n",
            " obalAveragePooling2D)                                                                            \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 4096)         0           ['global_max_pooling2d[0][0]',   \n",
            "                                                                  'global_average_pooling2d[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 4096)         0           ['global_max_pooling2d_1[0][0]', \n",
            "                                                                  'global_average_pooling2d_1[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " multiply_1 (Multiply)          (None, 4096)         0           ['concatenate[0][0]',            \n",
            "                                                                  'concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " multiply_2 (Multiply)          (None, 4096)         0           ['concatenate_1[0][0]',          \n",
            "                                                                  'concatenate_1[0][0]']          \n",
            "                                                                                                  \n",
            " subtract (Subtract)            (None, 4096)         0           ['concatenate[0][0]',            \n",
            "                                                                  'concatenate_1[0][0]']          \n",
            "                                                                                                  \n",
            " subtract_1 (Subtract)          (None, 4096)         0           ['multiply_1[0][0]',             \n",
            "                                                                  'multiply_2[0][0]']             \n",
            "                                                                                                  \n",
            " multiply (Multiply)            (None, 4096)         0           ['subtract[0][0]',               \n",
            "                                                                  'subtract[0][0]']               \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate)    (None, 8192)         0           ['subtract_1[0][0]',             \n",
            "                                                                  'multiply[0][0]']               \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 48)           393264      ['concatenate_2[0][0]']          \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 48)           0           ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 16)           784         ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)            (None, 16)           0           ['dense_1[0][0]']                \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 1)            17          ['dropout_1[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 23,955,217\n",
            "Trainable params: 394,065\n",
            "Non-trainable params: 23,561,152\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/100\n",
            "180/180 [==============================] - ETA: 0s - loss: 4.9404 - acc: 0.5740\n",
            "Epoch 00001: val_acc improved from -inf to 0.55078, saving model to vgg_face.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  layer_config = serialize_layer_fn(layer)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Memory usage after: [3204.109375]MB\n",
            "Memory usage after clean up: [3204.234375]MB\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r180/180 [==============================] - 78s 370ms/step - loss: 4.9404 - acc: 0.5740 - val_loss: 2.8401 - val_acc: 0.5508 - lr: 1.0000e-04\n",
            "Epoch 2/100\n",
            "180/180 [==============================] - ETA: 0s - loss: 2.3209 - acc: 0.5885\n",
            "Epoch 00002: val_acc improved from 0.55078 to 0.57187, saving model to vgg_face.h5\n",
            "Memory usage after: [3237.37890625]MB\n",
            "Memory usage after clean up: [3237.3359375]MB\n",
            "180/180 [==============================] - 69s 371ms/step - loss: 2.3209 - acc: 0.5885 - val_loss: 1.9031 - val_acc: 0.5719 - lr: 1.0000e-04\n",
            "Epoch 3/100\n",
            "180/180 [==============================] - ETA: 0s - loss: 1.5101 - acc: 0.6101\n",
            "Epoch 00003: val_acc improved from 0.57187 to 0.57500, saving model to vgg_face.h5\n",
            "Memory usage after: [3237.41015625]MB\n",
            "Memory usage after clean up: [3237.34765625]MB\n",
            "180/180 [==============================] - 69s 373ms/step - loss: 1.5101 - acc: 0.6101 - val_loss: 1.4325 - val_acc: 0.5750 - lr: 1.0000e-04\n",
            "Epoch 4/100\n",
            "180/180 [==============================] - ETA: 0s - loss: 1.1163 - acc: 0.6184\n",
            "Epoch 00004: val_acc did not improve from 0.57500\n",
            "Memory usage after: [3272.98046875]MB\n",
            "Memory usage after clean up: [3272.9140625]MB\n",
            "180/180 [==============================] - 68s 368ms/step - loss: 1.1163 - acc: 0.6184 - val_loss: 1.0870 - val_acc: 0.5672 - lr: 1.0000e-04\n",
            "Epoch 5/100\n",
            "180/180 [==============================] - ETA: 0s - loss: 0.8898 - acc: 0.6181\n",
            "Epoch 00005: val_acc improved from 0.57500 to 0.59688, saving model to vgg_face.h5\n",
            "Memory usage after: [3280.109375]MB\n",
            "Memory usage after clean up: [3280.046875]MB\n",
            "180/180 [==============================] - 85s 464ms/step - loss: 0.8898 - acc: 0.6181 - val_loss: 0.8498 - val_acc: 0.5969 - lr: 1.0000e-04\n",
            "Epoch 6/100\n",
            "180/180 [==============================] - ETA: 0s - loss: 0.7521 - acc: 0.6670\n",
            "Epoch 00006: val_acc did not improve from 0.59688\n",
            "Memory usage after: [3280.109375]MB\n",
            "Memory usage after clean up: [3280.046875]MB\n",
            "180/180 [==============================] - 85s 460ms/step - loss: 0.7521 - acc: 0.6670 - val_loss: 0.7736 - val_acc: 0.5781 - lr: 1.0000e-04\n",
            "Epoch 7/100\n",
            "180/180 [==============================] - ETA: 0s - loss: 0.7022 - acc: 0.6479\n",
            "Epoch 00007: val_acc improved from 0.59688 to 0.63203, saving model to vgg_face.h5\n",
            "Memory usage after: [3280.328125]MB\n",
            "Memory usage after clean up: [3280.2734375]MB\n",
            "180/180 [==============================] - 67s 363ms/step - loss: 0.7022 - acc: 0.6479 - val_loss: 0.6970 - val_acc: 0.6320 - lr: 1.0000e-04\n",
            "Epoch 8/100\n",
            "180/180 [==============================] - ETA: 0s - loss: 0.6818 - acc: 0.6712\n",
            "Epoch 00008: val_acc improved from 0.63203 to 0.63437, saving model to vgg_face.h5\n",
            "Memory usage after: [3280.36328125]MB\n",
            "Memory usage after clean up: [3280.3203125]MB\n",
            "180/180 [==============================] - 68s 367ms/step - loss: 0.6818 - acc: 0.6712 - val_loss: 0.7232 - val_acc: 0.6344 - lr: 1.0000e-04\n",
            "Epoch 9/100\n",
            "180/180 [==============================] - ETA: 0s - loss: 0.6686 - acc: 0.6677\n",
            "Epoch 00009: val_acc improved from 0.63437 to 0.66250, saving model to vgg_face.h5\n",
            "Memory usage after: [3280.4140625]MB\n",
            "Memory usage after clean up: [3280.3515625]MB\n",
            "180/180 [==============================] - 68s 369ms/step - loss: 0.6686 - acc: 0.6677 - val_loss: 0.6941 - val_acc: 0.6625 - lr: 1.0000e-04\n",
            "Epoch 10/100\n",
            "180/180 [==============================] - ETA: 0s - loss: 0.6387 - acc: 0.6806\n",
            "Epoch 00010: val_acc did not improve from 0.66250\n",
            "Memory usage after: [3280.45703125]MB\n",
            "Memory usage after clean up: [3280.37890625]MB\n",
            "180/180 [==============================] - 67s 362ms/step - loss: 0.6387 - acc: 0.6806 - val_loss: 0.7311 - val_acc: 0.6594 - lr: 1.0000e-04\n",
            "Epoch 11/100\n",
            "180/180 [==============================] - ETA: 0s - loss: 0.6333 - acc: 0.7042\n",
            "Epoch 00011: val_acc did not improve from 0.66250\n",
            "Memory usage after: [3280.44921875]MB\n",
            "Memory usage after clean up: [3280.37890625]MB\n",
            "180/180 [==============================] - 66s 358ms/step - loss: 0.6333 - acc: 0.7042 - val_loss: 0.7581 - val_acc: 0.6555 - lr: 1.0000e-04\n",
            "Epoch 12/100\n",
            "180/180 [==============================] - ETA: 0s - loss: 0.5851 - acc: 0.7038\n",
            "Epoch 00012: val_acc did not improve from 0.66250\n",
            "Memory usage after: [3280.46484375]MB\n",
            "Memory usage after clean up: [3280.3828125]MB\n",
            "180/180 [==============================] - 68s 364ms/step - loss: 0.5851 - acc: 0.7038 - val_loss: 0.7449 - val_acc: 0.6477 - lr: 1.0000e-04\n",
            "Epoch 13/100\n",
            "180/180 [==============================] - ETA: 0s - loss: 0.5817 - acc: 0.7097\n",
            "Epoch 00013: val_acc improved from 0.66250 to 0.68359, saving model to vgg_face.h5\n",
            "Memory usage after: [3280.68359375]MB\n",
            "Memory usage after clean up: [3280.62109375]MB\n",
            "180/180 [==============================] - 69s 368ms/step - loss: 0.5817 - acc: 0.7097 - val_loss: 0.8779 - val_acc: 0.6836 - lr: 1.0000e-04\n",
            "Epoch 14/100\n",
            "180/180 [==============================] - ETA: 0s - loss: 0.5754 - acc: 0.7094\n",
            "Epoch 00014: val_acc improved from 0.68359 to 0.68437, saving model to vgg_face.h5\n",
            "Memory usage after: [3280.6796875]MB\n",
            "Memory usage after clean up: [3280.63671875]MB\n",
            "180/180 [==============================] - 68s 364ms/step - loss: 0.5754 - acc: 0.7094 - val_loss: 0.7714 - val_acc: 0.6844 - lr: 1.0000e-04\n",
            "Epoch 15/100\n",
            "180/180 [==============================] - ETA: 0s - loss: 0.5871 - acc: 0.7115\n",
            "Epoch 00015: val_acc did not improve from 0.68437\n",
            "Memory usage after: [3280.73828125]MB\n",
            "Memory usage after clean up: [3280.63671875]MB\n",
            "180/180 [==============================] - 67s 364ms/step - loss: 0.5871 - acc: 0.7115 - val_loss: 0.7936 - val_acc: 0.6383 - lr: 1.0000e-04\n",
            "Epoch 16/100\n",
            "180/180 [==============================] - ETA: 0s - loss: 0.5716 - acc: 0.7125\n",
            "Epoch 00016: val_acc did not improve from 0.68437\n",
            "Memory usage after: [3280.73828125]MB\n",
            "Memory usage after clean up: [3280.63671875]MB\n",
            "180/180 [==============================] - 68s 367ms/step - loss: 0.5716 - acc: 0.7125 - val_loss: 0.8223 - val_acc: 0.6492 - lr: 1.0000e-04\n",
            "Epoch 17/100\n",
            "180/180 [==============================] - ETA: 0s - loss: 0.5448 - acc: 0.7250\n",
            "Epoch 00017: val_acc did not improve from 0.68437\n",
            "Memory usage after: [3280.703125]MB\n",
            "Memory usage after clean up: [3280.640625]MB\n",
            "180/180 [==============================] - 85s 458ms/step - loss: 0.5448 - acc: 0.7250 - val_loss: 0.7518 - val_acc: 0.6727 - lr: 1.0000e-04\n",
            "Epoch 18/100\n",
            "180/180 [==============================] - ETA: 0s - loss: 0.5839 - acc: 0.7212\n",
            "Epoch 00018: val_acc did not improve from 0.68437\n",
            "Memory usage after: [3294.94921875]MB\n",
            "Memory usage after clean up: [3294.84765625]MB\n",
            "180/180 [==============================] - 68s 363ms/step - loss: 0.5839 - acc: 0.7212 - val_loss: 0.8050 - val_acc: 0.6531 - lr: 1.0000e-04\n",
            "Epoch 19/100\n",
            "180/180 [==============================] - ETA: 0s - loss: 0.5322 - acc: 0.7437\n",
            "Epoch 00019: val_acc did not improve from 0.68437\n",
            "Memory usage after: [3294.91015625]MB\n",
            "Memory usage after clean up: [3294.84765625]MB\n",
            "180/180 [==============================] - 84s 456ms/step - loss: 0.5322 - acc: 0.7437 - val_loss: 0.8327 - val_acc: 0.6602 - lr: 1.0000e-04\n",
            "Epoch 20/100\n",
            "180/180 [==============================] - ETA: 0s - loss: 0.5412 - acc: 0.7333\n",
            "Epoch 00020: val_acc did not improve from 0.68437\n",
            "Memory usage after: [3294.91015625]MB\n",
            "Memory usage after clean up: [3294.84765625]MB\n",
            "180/180 [==============================] - 85s 460ms/step - loss: 0.5412 - acc: 0.7333 - val_loss: 0.7658 - val_acc: 0.6773 - lr: 1.0000e-04\n",
            "Epoch 21/100\n",
            "180/180 [==============================] - ETA: 0s - loss: 0.5342 - acc: 0.7240\n",
            "Epoch 00021: val_acc did not improve from 0.68437\n",
            "Memory usage after: [3294.91796875]MB\n",
            "Memory usage after clean up: [3294.84765625]MB\n",
            "180/180 [==============================] - 69s 371ms/step - loss: 0.5342 - acc: 0.7240 - val_loss: 0.9111 - val_acc: 0.6695 - lr: 1.0000e-04\n",
            "Epoch 22/100\n",
            "180/180 [==============================] - ETA: 0s - loss: 0.5382 - acc: 0.7424\n",
            "Epoch 00022: val_acc did not improve from 0.68437\n",
            "Memory usage after: [3294.91015625]MB\n",
            "Memory usage after clean up: [3294.84765625]MB\n",
            "180/180 [==============================] - 85s 459ms/step - loss: 0.5382 - acc: 0.7424 - val_loss: 0.7621 - val_acc: 0.6742 - lr: 1.0000e-04\n",
            "Epoch 23/100\n",
            "180/180 [==============================] - ETA: 0s - loss: 0.5228 - acc: 0.7486\n",
            "Epoch 00023: val_acc did not improve from 0.68437\n",
            "Memory usage after: [3294.953125]MB\n",
            "Memory usage after clean up: [3294.8515625]MB\n",
            "180/180 [==============================] - 68s 366ms/step - loss: 0.5228 - acc: 0.7486 - val_loss: 0.8092 - val_acc: 0.6523 - lr: 1.0000e-04\n",
            "Epoch 24/100\n",
            "180/180 [==============================] - ETA: 0s - loss: 0.5094 - acc: 0.7493\n",
            "Epoch 00024: val_acc did not improve from 0.68437\n",
            "\n",
            "Epoch 00024: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
            "Memory usage after: [3294.953125]MB\n",
            "Memory usage after clean up: [3294.8515625]MB\n",
            "180/180 [==============================] - 68s 366ms/step - loss: 0.5094 - acc: 0.7493 - val_loss: 0.8549 - val_acc: 0.6438 - lr: 1.0000e-04\n",
            "Epoch 25/100\n",
            "180/180 [==============================] - ETA: 0s - loss: 0.5227 - acc: 0.7611\n",
            "Epoch 00025: val_acc did not improve from 0.68437\n",
            "Memory usage after: [3294.953125]MB\n",
            "Memory usage after clean up: [3294.8515625]MB\n",
            "180/180 [==============================] - 67s 362ms/step - loss: 0.5227 - acc: 0.7611 - val_loss: 0.9975 - val_acc: 0.6523 - lr: 1.0000e-05\n",
            "Epoch 26/100\n",
            "180/180 [==============================] - ETA: 0s - loss: 0.5222 - acc: 0.7566\n",
            "Epoch 00026: val_acc did not improve from 0.68437\n",
            "Memory usage after: [3294.95703125]MB\n",
            "Memory usage after clean up: [3294.85546875]MB\n",
            "180/180 [==============================] - 67s 361ms/step - loss: 0.5222 - acc: 0.7566 - val_loss: 0.7662 - val_acc: 0.6602 - lr: 1.0000e-05\n",
            "Epoch 27/100\n",
            "180/180 [==============================] - ETA: 0s - loss: 0.5166 - acc: 0.7455\n",
            "Epoch 00027: val_acc did not improve from 0.68437\n",
            "Memory usage after: [3309.12890625]MB\n",
            "Memory usage after clean up: [3309.05078125]MB\n",
            "180/180 [==============================] - 67s 360ms/step - loss: 0.5166 - acc: 0.7455 - val_loss: 0.9725 - val_acc: 0.6445 - lr: 1.0000e-05\n",
            "Epoch 28/100\n",
            "180/180 [==============================] - ETA: 0s - loss: 0.5069 - acc: 0.7486\n",
            "Epoch 00028: val_acc did not improve from 0.68437\n",
            "Memory usage after: [3309.16015625]MB\n",
            "Memory usage after clean up: [3309.09765625]MB\n",
            "180/180 [==============================] - 83s 453ms/step - loss: 0.5069 - acc: 0.7486 - val_loss: 0.8796 - val_acc: 0.6555 - lr: 1.0000e-05\n",
            "Epoch 29/100\n",
            "180/180 [==============================] - ETA: 0s - loss: 0.4829 - acc: 0.7601\n",
            "Epoch 00029: val_acc did not improve from 0.68437\n",
            "Memory usage after: [3310.14453125]MB\n",
            "Memory usage after clean up: [3310.07421875]MB\n",
            "180/180 [==============================] - 66s 356ms/step - loss: 0.4829 - acc: 0.7601 - val_loss: 0.9111 - val_acc: 0.6414 - lr: 1.0000e-05\n",
            "Epoch 30/100\n",
            "180/180 [==============================] - ETA: 0s - loss: 0.4764 - acc: 0.7635\n",
            "Epoch 00030: val_acc did not improve from 0.68437\n",
            "Memory usage after: [3310.6015625]MB\n",
            "Memory usage after clean up: [3310.5]MB\n",
            "180/180 [==============================] - 67s 359ms/step - loss: 0.4764 - acc: 0.7635 - val_loss: 0.9248 - val_acc: 0.6625 - lr: 1.0000e-05\n",
            "Epoch 31/100\n",
            "180/180 [==============================] - ETA: 0s - loss: 0.5055 - acc: 0.7514\n",
            "Epoch 00031: val_acc did not improve from 0.68437\n",
            "Memory usage after: [3339.16015625]MB\n",
            "Memory usage after clean up: [3339.05859375]MB\n",
            "180/180 [==============================] - 66s 358ms/step - loss: 0.5055 - acc: 0.7514 - val_loss: 0.9795 - val_acc: 0.6406 - lr: 1.0000e-05\n",
            "Epoch 32/100\n",
            "180/180 [==============================] - ETA: 0s - loss: 0.5014 - acc: 0.7490\n",
            "Epoch 00032: val_acc did not improve from 0.68437\n",
            "Memory usage after: [3339.125]MB\n",
            "Memory usage after clean up: [3339.046875]MB\n",
            "180/180 [==============================] - 66s 355ms/step - loss: 0.5014 - acc: 0.7490 - val_loss: 0.7584 - val_acc: 0.6773 - lr: 1.0000e-05\n",
            "Epoch 33/100\n",
            "180/180 [==============================] - ETA: 0s - loss: 0.5241 - acc: 0.7569\n",
            "Epoch 00033: val_acc did not improve from 0.68437\n",
            "Memory usage after: [3339.109375]MB\n",
            "Memory usage after clean up: [3339.046875]MB\n",
            "180/180 [==============================] - 83s 453ms/step - loss: 0.5241 - acc: 0.7569 - val_loss: 0.8581 - val_acc: 0.6383 - lr: 1.0000e-05\n",
            "Epoch 34/100\n",
            "180/180 [==============================] - ETA: 0s - loss: 0.4867 - acc: 0.7639\n",
            "Epoch 00034: val_acc did not improve from 0.68437\n",
            "\n",
            "Epoch 00034: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
            "Memory usage after: [3339.109375]MB\n",
            "Memory usage after clean up: [3339.046875]MB\n",
            "180/180 [==============================] - 84s 455ms/step - loss: 0.4867 - acc: 0.7639 - val_loss: 0.8562 - val_acc: 0.6422 - lr: 1.0000e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWqVHNzgcQk5"
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "hmAN6PQD2Aw1",
        "outputId": "7cb54001-b09a-47e4-cfc8-8e12cb5b4567"
      },
      "source": [
        "fig,ax=plt.subplots(1,1)\n",
        "acc=result.history['acc']\n",
        "val_acc=result.history['val_acc']\n",
        "ax.plot(acc,label=\"train\")\n",
        "ax.plot(val_acc,label=\"test\")\n",
        "ax.set_title(\"vgg_face.h5(2)\")\n",
        "    "
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'vgg_face.h5(2)')"
            ]
          },
          "metadata": {},
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLb21vJ_cSaY"
      },
      "source": [
        "fig,ax=plt.subplots(10,1)\n",
        "for i in range(10):\n",
        "    r=-3*np.random.rand()-1\n",
        "    lr=pow(10,r)\n",
        "    print(lr,r)\n",
        "    model=baseline_model(learning_rate=lr)\n",
        "    result=model.fit(train_gen, use_multiprocessing=True,\n",
        "                    validation_data=val_gen, epochs=100, verbose=1,\n",
        "                    workers = 4, callbacks=callbacks_list, steps_per_epoch=200, validation_steps=80)\n",
        "    acc=result.history['accuracy']\n",
        "    val_acc=result.history['val_acc']\n",
        "    ax[i].plot(acc,label=\"train\")\n",
        "    ax[i].plot(val_acc,label=\"test\")\n",
        "    ax[i].set_title(\"learning rate=\"+str(lr))\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EiI7Pf9YvwEA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}